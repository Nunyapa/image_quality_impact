{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models.common'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c489c54c16b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtest\u001b[0m  \u001b[1;31m# import test.py to get mAP after each epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolov5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mattempt_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoanchor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_anchors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\diploma\\models\\yolov5\\models\\experimental.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDWConv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoogle_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mattempt_download\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models.common'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.utils.data\n",
    "import yaml\n",
    "from torch.cuda import amp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import test  # import test.py to get mAP after each epoch\n",
    "from models.experimental import attempt_load\n",
    "from models.yolo import Model\n",
    "from utils.autoanchor import check_anchors\n",
    "from utils.datasets import create_dataloader\n",
    "from utils.general import labels_to_class_weights, increment_path, labels_to_image_weights, init_seeds, \\\n",
    "    fitness, strip_optimizer, get_latest_run, check_dataset, check_file, check_git_status, check_img_size, \\\n",
    "    check_requirements, print_mutation, set_logging, one_cycle, colorstr\n",
    "from utils.google_utils import attempt_download\n",
    "from utils.loss import ComputeLoss\n",
    "from utils.plots import plot_images, plot_labels, plot_results, plot_evolution\n",
    "from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()\n",
    "print('Setup complete. Using torch %s %s' % \n",
    "      (torch.__version__, \n",
    "       torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU')\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%cd D:\\diploma\\models\\\n",
    "\n",
    "yaml_path = r'D:\\diploma\\models\\data.yaml'\n",
    "with open(yaml_path, 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 416 \n",
    "                --batch 64 \n",
    "                --epochs 100 \n",
    "                --data \"D:\\diploma\\Diploma project\\Dataset\\data.yaml\" \n",
    "                --cfg ./models/yolov5s_custom.yaml \n",
    "                --weights '' \n",
    "                --name YoloBaseline \n",
    "                --nosave \n",
    "                --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--quad'], dest='quad', nargs=0, const=True, default=False, type=None, choices=None, help='quad dataloader', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--weights', type=str, default='yolov5s.pt', help='initial weights path')\n",
    "parser.add_argument('--cfg', type=str, default='', help='model.yaml path')\n",
    "parser.add_argument('--data', type=str, default='data/coco128.yaml', help='data.yaml path')\n",
    "parser.add_argument('--hyp', type=str, default='data/hyp.scratch.yaml', help='hyperparameters path')\n",
    "parser.add_argument('--epochs', type=int, default=300)\n",
    "parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs')\n",
    "parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='[train, test] image sizes')\n",
    "parser.add_argument('--rect', action='store_true', help='rectangular training')\n",
    "parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')\n",
    "parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n",
    "parser.add_argument('--notest', action='store_true', help='only test final epoch')\n",
    "parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')\n",
    "parser.add_argument('--evolve', action='store_true', help='evolve hyperparameters')\n",
    "parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n",
    "parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')\n",
    "parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')\n",
    "parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')\n",
    "parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')\n",
    "parser.add_argument('--adam', action='store_true', help='use torch.optim.Adam() optimizer')\n",
    "parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')\n",
    "parser.add_argument('--local_rank', type=int, default=-1, help='DDP parameter, do not modify')\n",
    "parser.add_argument('--log-imgs', type=int, default=16, help='number of images for W&B logging, max 100')\n",
    "parser.add_argument('--log-artifacts', action='store_true', help='log artifacts, i.e. final trained model')\n",
    "parser.add_argument('--workers', type=int, default=8, help='maximum number of dataloader workers')\n",
    "parser.add_argument('--project', default='runs/train', help='save to project/name')\n",
    "parser.add_argument('--name', default='exp', help='save to project/name')\n",
    "parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
    "parser.add_argument('--quad', action='store_true', help='quad dataloader')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParameters:\n",
    "    \n",
    "    def __init__(self,\n",
    "                weights = 'yolov5s.pt',\n",
    "                cfg = '',\n",
    "                data='data/coco128.yaml',\n",
    "                hyp='data/hyp.scratch.yaml',\n",
    "                epochs=300,\n",
    "                batch=16,\n",
    "                img_size=[640, 640],\n",
    "                rect = True,\n",
    "                resume=False,\n",
    "                nosave=True,\n",
    "                notest=True,\n",
    "                noautoanchor=True,\n",
    "                evolve=True,\n",
    "                bucket='',\n",
    "                cache_images=True,\n",
    "                image_weights=True,\n",
    "                device='',\n",
    "                multi_scale=True,\n",
    "                single_cls=True,\n",
    "                adam=True,\n",
    "                sync_bn=True,\n",
    "                local_rank=-1,\n",
    "                log_imgs=16,\n",
    "                log_artifacts=True,\n",
    "                workers=8,\n",
    "                project='runs/train',\n",
    "                name='exp',\n",
    "                exist_ok=True,\n",
    "                quad=True):\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.cfg = cfg\n",
    "        self.data = data\n",
    "        self.hyp = hyp\n",
    "        self.epochs = epochs\n",
    "        self.batch = batch\n",
    "        self.img_size = img_size\n",
    "        self.rect = rect\n",
    "        self.resume = resume\n",
    "        self.nosave = nosave\n",
    "        self.notest = notest\n",
    "        self.noautoanchor = noautoanchor\n",
    "        self.evolve = evolve\n",
    "        self.bucket = bucket\n",
    "        self.cache_images = cache_images\n",
    "        self.image_weights = image_weights\n",
    "        self.device = device\n",
    "        self.multi_scale = multi_scale\n",
    "        self.single_cls = single_cls\n",
    "        self.adam = adam\n",
    "        self.sync_bn = sync_bn\n",
    "        self.local_rank = local_rank\n",
    "        self.log_imgs = log_imgs\n",
    "        self.log_artifacts = log_artifacts\n",
    "        self.workers = workers\n",
    "        self.project = project\n",
    "        self.name = name\n",
    "        self.exist_ok = exist_ok\n",
    "        self.quad = quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'set_logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-04c27253853b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworld_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'WORLD_SIZE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'WORLD_SIZE'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RANK'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'RANK'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mset_logging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_rank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_rank\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcheck_git_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'set_logging' is not defined"
     ]
    }
   ],
   "source": [
    "opt = ModelParameters()\n",
    "\n",
    "# Set DDP variables\n",
    "opt.world_size = int(os.environ['WORLD_SIZE']) if 'WORLD_SIZE' in os.environ else 1\n",
    "opt.global_rank = int(os.environ['RANK']) if 'RANK' in os.environ else -1\n",
    "set_logging(opt.global_rank)\n",
    "if opt.global_rank in [-1, 0]:\n",
    "    check_git_status()\n",
    "    check_requirements()\n",
    "\n",
    "# Resume\n",
    "if opt.resume:  # resume an interrupted run\n",
    "    ckpt = opt.resume if isinstance(opt.resume, str) else get_latest_run()  # specified or most recent path\n",
    "    assert os.path.isfile(ckpt), 'ERROR: --resume checkpoint does not exist'\n",
    "    apriori = opt.global_rank, opt.local_rank\n",
    "    with open(Path(ckpt).parent.parent / 'opt.yaml') as f:\n",
    "        opt = argparse.Namespace(**yaml.load(f, Loader=yaml.FullLoader))  # replace\n",
    "    opt.cfg, opt.weights, opt.resume, opt.batch_size, opt.global_rank, opt.local_rank = '', ckpt, True, opt.total_batch_size, *apriori  # reinstate\n",
    "    logger.info('Resuming training from %s' % ckpt)\n",
    "else:\n",
    "    # opt.hyp = opt.hyp or ('hyp.finetune.yaml' if opt.weights else 'hyp.scratch.yaml')\n",
    "    opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files\n",
    "    assert len(opt.cfg) or len(opt.weights), 'either --cfg or --weights must be specified'\n",
    "    opt.img_size.extend([opt.img_size[-1]] * (2 - len(opt.img_size)))  # extend to 2 sizes (train, test)\n",
    "    opt.name = 'evolve' if opt.evolve else opt.name\n",
    "    opt.save_dir = increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok | opt.evolve)  # increment run\n",
    "\n",
    "# DDP mode\n",
    "opt.total_batch_size = opt.batch_size\n",
    "device = select_device(opt.device, batch_size=opt.batch_size)\n",
    "if opt.local_rank != -1:\n",
    "    assert torch.cuda.device_count() > opt.local_rank\n",
    "    torch.cuda.set_device(opt.local_rank)\n",
    "    device = torch.device('cuda', opt.local_rank)\n",
    "    dist.init_process_group(backend='nccl', init_method='env://')  # distributed backend\n",
    "    assert opt.batch_size % opt.world_size == 0, '--batch-size must be multiple of CUDA device count'\n",
    "    opt.batch_size = opt.total_batch_size // opt.world_size\n",
    "\n",
    "# Hyperparameters\n",
    "with open(opt.hyp) as f:\n",
    "    hyp = yaml.load(f, Loader=yaml.FullLoader)  # load hyps\n",
    "\n",
    "# Train\n",
    "logger.info(opt)\n",
    "try:\n",
    "    import wandb\n",
    "except ImportError:\n",
    "    wandb = None\n",
    "    prefix = colorstr('wandb: ')\n",
    "    logger.info(f\"{prefix}Install Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\")\n",
    "if not opt.evolve:\n",
    "    tb_writer = None  # init loggers\n",
    "    if opt.global_rank in [-1, 0]:\n",
    "        logger.info(f'Start Tensorboard with \"tensorboard --logdir {opt.project}\", view at http://localhost:6006/')\n",
    "        tb_writer = SummaryWriter(opt.save_dir)  # Tensorboard\n",
    "    train(hyp, opt, device, tb_writer, wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
